{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74d2404e-350b-44b1-bce2-b9bc63a74bd2",
   "metadata": {},
   "source": [
    "# Address Parsing NLP \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d215f7-7ee9-42a8-816f-dd62c14d7e3f",
   "metadata": {},
   "source": [
    "<h1> Introduction </h1>\n",
    "\n",
    "Address parsing is something that requires tedious manual work. There are tools that can be used like QAS, Oracles Quick Address Search. QAS,\n",
    "although is a great resource is very rigid and predetermined using rigid algoriths. Often time addresses need preprocessing to be utilized by QAS especially when address strings contain additional information. Natural Language Processing (NLP) is a great resource to parse addresses from large strings with addition information. NLPs are highly adaptable and capable of learning specific requirements which can be easily determined by training data. The only requirement for fine tuning of the data requirement is a lot of data.\n",
    "\n",
    "\n",
    "In this notebook, we will extract address from large dataset in which the address strings are in various formats. The dataset was taken from  [Indiana Department of Environmental Management](<https://www.in.gov/idem/cleanups/investigation-and-cleanup-programs/emergency-response/>). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c247f-ca61-4912-9a02-c4fdee650f04",
   "metadata": {},
   "source": [
    "<h1>Prerequisites</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbde458b-2e4a-412f-aaae-cdafc6aeee96",
   "metadata": {},
   "source": [
    "- Data Preparations:\n",
    "    - Need a cleaned dataset. I have cleaned around 300 records from this dataset using regular expressions\n",
    " \n",
    "- Model Training Workflow & Library\n",
    "    - we will be using [spaCy](<https://spacy.io/usage/spacy-101>). a library which deals with large strings and training NLPS\n",
    "    - this library uses Named Entity Recognition (NER) which is a method to extract and categorize information withing text.\n",
    "    - this model will extract subsections of the data and categorize them.\n",
    " \n",
    "  \n",
    "Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4021aafe-b6f0-4b6c-b28b-f0f88119d9cc",
   "metadata": {},
   "source": [
    "<!-- Markdown -->\n",
    "<div style=\"overflow-x:auto;\">\n",
    "    <table style=\"width:100%; margin-left: 0;\">\n",
    "        <thead>\n",
    "            <tr>\n",
    "                <th style=\"text-align:left;\">Raw Location String</th>\n",
    "                <th style=\"text-align:left;\">Parsed Address</th>\n",
    "                <th style=\"text-align:left;\">Parsed City</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "            <tr>\n",
    "                <td style=\"text-align:left;\">123 Something St. Tronto  </td>\n",
    "                <td style=\"text-align:left;\">123 Something St. </td>\n",
    "                <td style=\"text-align:left;\">Tronto</td>\n",
    "            </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af69b3-82e9-4f8d-9f74-5bc835873231",
   "metadata": {},
   "source": [
    "- despite 'Tronto' being spelt wrong the parsing will only take a subsection of the text. This although does not correct everything, it ensures the data is a subsection of the data. In the future, we can make a seperate NLP to correct spelling and common mistakes in city values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584dee8f-0a8d-4da2-8b46-7f8208d9102e",
   "metadata": {},
   "source": [
    "<h1>Necessary Imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6051ec52-9e51-4f76-8f58-48dd06d1f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563a6e48-7e2e-4279-9395-5f0a5b336799",
   "metadata": {},
   "source": [
    "<h1>Data Preparation</h1>\n",
    "Things I have learned working with spaCy:\n",
    "\n",
    "1. the parsed data must be a subset of the original string\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e39853-deac-4647-ba15-ba7daab62939",
   "metadata": {},
   "source": [
    "<!-- Markdown -->\n",
    "<div style=\"overflow-x:auto;\">\n",
    "    <table style=\"width:100%; margin-left: 0;\">\n",
    "        <thead>\n",
    "            <tr>\n",
    "                <th style=\"text-align:left;\">Is it Problematic</th>\n",
    "                <th style=\"text-align:left;\">Raw Location String</th>\n",
    "                <th style=\"text-align:left;\">Parsed Address</th>\n",
    "                <th style=\"text-align:left;\">Parsed City</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "            <tr>\n",
    "                <th style=\"text-align:left;\">No</th>\n",
    "                <td style=\"text-align:left;\">123 Something St. Tronto  </td>\n",
    "                <td style=\"text-align:left;\">123 Something St. </td>\n",
    "                <td style=\"text-align:left;\">Tronto</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th style=\"text-align:left;\">Yes</th>\n",
    "                <td style=\"text-align:left;\">123 Something St. Tronto  </td>\n",
    "                <td style=\"text-align:left;\">123 Something Street </td>\n",
    "                <td style=\"text-align:left;\">Toronto</td>\n",
    "            </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6785ef8c-95f2-4cd5-a980-8f96ae9f8107",
   "metadata": {},
   "source": [
    "Notice that the second row in the Parsed Address column there 'Street' instead of 'St.'. Since 'St.' isn't readily found in the original string there is going to be an error. Notice in the Parsed City columns 'Toronto' is fixed so 'Toronto isn't found in the original string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7a234b-d325-4fb1-9594-5bf8c3b969cc",
   "metadata": {},
   "source": [
    "2. two seperate entities must not over lap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f837a1-28f0-4c2f-b8fe-59e254286f73",
   "metadata": {},
   "source": [
    "<!-- Markdown -->\n",
    "<div style=\"overflow-x:auto;\">\n",
    "    <table style=\"width:100%; margin-left: 0;\">\n",
    "        <thead>\n",
    "            <tr>\n",
    "                <th style=\"text-align:left;\">Is it Problematic</th>\n",
    "                <th style=\"text-align:left;\">Raw Location String</th>\n",
    "                <th style=\"text-align:left;\">Parsed Address</th>\n",
    "                <th style=\"text-align:left;\">Parsed City</th>\n",
    "                <th style=\"text-align:left;\">Parsed Prov</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "            <tr>\n",
    "                <th style=\"text-align:left;\">No</th>\n",
    "                <td style=\"text-align:left;\">123 Onnis St. Tronto  Nt</td>\n",
    "                <td style=\"text-align:left;\">123 Onnis St. </td>\n",
    "                <td style=\"text-align:left;\">Tronto</td>\n",
    "                <td style=\"text-align:left;\">Nt</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th style=\"text-align:left;\">Yes</th>\n",
    "                <td style=\"text-align:left;\">123 Onnis St. Tronto  On</td>\n",
    "                <td style=\"text-align:left;\">123 Onnis St. </td>\n",
    "                <td style=\"text-align:left;\">Tronto</td>\n",
    "                <td style=\"text-align:left;\">On</td>\n",
    "            </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf55c0e-024b-46a7-aef6-ece595c538ec",
   "metadata": {},
   "source": [
    "Notice in the second row, there are two places where the string 'On' is in the Raw Location String: 123 __On__ nis St. Tronto  __On__. This causes issues when using specific methods in spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c399760-14e8-4ac2-b320-c144a5412858",
   "metadata": {},
   "source": [
    "<h1>Data Cleaning, Data Training, Validation & Test Subset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551ce56d-6169-4f67-8293-e227a3d7f565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| LOCATION                                                                    | ADDRESS                | CITY         |   ZIP |   X |   Y |\n",
      "|:----------------------------------------------------------------------------|:-----------------------|:-------------|------:|----:|----:|\n",
      "| PEARL ST   LAUREL IN  FRANKLIN CO                                           | nan                    | LAUREL       |   nan | nan | nan |\n",
      "| 200 Trowbridge Rd  Indianapolis, Marion Co  INDIANA RR YARD                 | 200 Trowbridge Rd      | Indianapolis |   nan | nan | nan |\n",
      "| 487 Corn Creek Road  Bedford, KY                                            | 487 Corn Creek Road    | Bedford      |   nan | nan | nan |\n",
      "| Ohio River, River Mile 475  Cincinnati, OH                                  | nan                    | Cincinnati   |   nan | nan | nan |\n",
      "| 2403 US 31 LOT 51  PLYMOUTH  MARSHALL CO                                    | 2403 US 31             | PLYMOUTH     |   nan | nan | nan |\n",
      "| Marion County  3041 E  Bradbury Ave.  Indianapolis, IN                      | 3041 E  Bradbury Ave.  | Indianapolis |   nan | nan | nan |\n",
      "| SR 75 AND WINTER KING DR  DANVILLE IN  HENDRICKS CO                         | SR 75 & WINTER KING DR | DANVILLE     |   nan | nan | nan |\n",
      "| FLOYD CO  NEW ALBANY  2710 GRANT LINE RD  50 YARDS IMPACTED ALONG RAIL SPUR | 2710 GRANT LINE RD     | NEW ALBANY   |   nan | nan | nan |\n",
      "| MP 3.0                                                                      | nan                    | nan          |   nan | nan | nan |\n",
      "| 25915 SE Frontage Rd  Channahon, IL  60410                                  | 25915 SE Frontage Rd   | Channahon    | 60410 | nan | nan |\n",
      "| 58 Wescor Dr  Hawesville, KY  42348                                         | 58 Wescor Dr           | Hawesville   | 42348 | nan | nan |\n",
      "| Mile post B0.0 to B 2.9  Chicago, IL                                        | nan                    | Chicago      |   nan | nan | nan |\n",
      "| 1615 E EPLER AVE  INDIANAPOLIS                                              | 1615 E EPLER AVE       | INDIANAPOLIS |   nan | nan | nan |\n",
      "| Marion County  8 E Meridian School Rd  Indianapolis, In                     | 8 E Meridian School Rd | Indianapolis |   nan | nan | nan |\n",
      "| Lake County  RT 80 & Kennedy Ave  Hammond, IN                               | RT 80 & Kennedy Ave    | Hammond      |   nan | nan | nan |\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "\n",
    "df=pd.read_csv(\"ADDRESS_TRAINING_DATA_CLEANED.csv\",sep=\",\",dtype=str)\n",
    "\n",
    "# Example of data\n",
    "print(df.head(15).to_markdown(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db3472ab-353f-412b-9bfb-4df187130369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| LOCATION                                                                    | ADDRESS                  | CITY         |   ZIP |   X |   Y |\n",
      "|:----------------------------------------------------------------------------|:-------------------------|:-------------|------:|----:|----:|\n",
      "| PEARL ST   LAUREL IN  FRANKLIN CO                                           | nan                      | LAUREL       |   nan | nan | nan |\n",
      "| 200 TROWBRIDGE RD  INDIANAPOLIS, MARION CO  INDIANA RR YARD                 | 200 TROWBRIDGE RD        | INDIANAPOLIS |   nan | nan | nan |\n",
      "| 487 CORN CREEK ROAD  BEDFORD, KY                                            | 487 CORN CREEK ROAD      | BEDFORD      |   nan | nan | nan |\n",
      "| OHIO RIVER, RIVER MILE 475  CINCINNATI, OH                                  | nan                      | CINCINNATI   |   nan | nan | nan |\n",
      "| 2403 US 31 LOT 51  PLYMOUTH  MARSHALL CO                                    | 2403 US 31               | PLYMOUTH     |   nan | nan | nan |\n",
      "| MARION COUNTY  3041 E  BRADBURY AVE.  INDIANAPOLIS, IN                      | 3041 E  BRADBURY AVE.    | INDIANAPOLIS |   nan | nan | nan |\n",
      "| SR 75 AND WINTER KING DR  DANVILLE IN  HENDRICKS CO                         | SR 75 AND WINTER KING DR | DANVILLE     |   nan | nan | nan |\n",
      "| FLOYD CO  NEW ALBANY  2710 GRANT LINE RD  50 YARDS IMPACTED ALONG RAIL SPUR | 2710 GRANT LINE RD       | NEW ALBANY   |   nan | nan | nan |\n",
      "| MP 3.0                                                                      | nan                      | nan          |   nan | nan | nan |\n",
      "| 25915 SE FRONTAGE RD  CHANNAHON, IL  60410                                  | 25915 SE FRONTAGE RD     | CHANNAHON    | 60410 | nan | nan |\n",
      "| 58 WESCOR DR  HAWESVILLE, KY  42348                                         | 58 WESCOR DR             | HAWESVILLE   | 42348 | nan | nan |\n",
      "| MILE POST B0.0 TO B 2.9  CHICAGO, IL                                        | nan                      | CHICAGO      |   nan | nan | nan |\n",
      "| 1615 E EPLER AVE  INDIANAPOLIS                                              | 1615 E EPLER AVE         | INDIANAPOLIS |   nan | nan | nan |\n",
      "| MARION COUNTY  8 E MERIDIAN SCHOOL RD  INDIANAPOLIS, IN                     | 8 E MERIDIAN SCHOOL RD   | INDIANAPOLIS |   nan | nan | nan |\n",
      "| LAKE COUNTY  RT 80 AND KENNEDY AVE  HAMMOND, IN                             | RT 80 AND KENNEDY AVE    | HAMMOND      |   nan | nan | nan |\n"
     ]
    }
   ],
   "source": [
    "def file_specific_cleaning(df_train):\n",
    "\n",
    "    # 1. uppercase everything\n",
    "\n",
    "    # Convert all string columns to uppercase\n",
    "    # df_train = df_train.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "    df_train = df_train.apply(lambda x: x.str.upper() if x.dtype == \"object\" else x)\n",
    "\n",
    "\n",
    "    # 2. all &'s in the address field must be AND\n",
    "\n",
    "    df_train['ADDRESS'] =  df_train['ADDRESS'] .str.replace('&', 'AND').str.upper()\n",
    "    df_train['ADDRESS'] =  df_train['ADDRESS'] .str.replace('@', 'AND').str.upper()\n",
    "\n",
    "\n",
    "    # 3. escape characters: for example + or /. this is an issue for regular expressions so we have to escape them\n",
    "    def escape_non_nan(value):\n",
    "        if pd.isna(value):\n",
    "            return value\n",
    "        return re.escape(value)\n",
    "    \n",
    "    # Apply the function to the ADDRESS column\n",
    "    # df_train['ADDRESS'] = df_train['ADDRESS'].apply(escape_non_nan)\n",
    "    df_train['Y'] = df_train['Y'].apply(escape_non_nan)\n",
    "\n",
    "    # 4. all the @ in the Location to &\n",
    "\n",
    "    df_train['LOCATION'] =  df_train['LOCATION'] .str.replace('@', '&').str.upper()\n",
    "    df_train['LOCATION'] =  df_train['LOCATION'] .str.replace('&', 'AND').str.upper()\n",
    "\n",
    "    return df_train\n",
    "\n",
    "df=file_specific_cleaning(df)\n",
    "print(df.head(15).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d847e4a0-2230-4c8a-964a-692aad56ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove problematic records from above;\n",
    "\n",
    "# This span function outputs the indexes of the parased data. We will do a check to see if any of these values are  null\n",
    "\n",
    "def get_address_span(address=None,address_component=None,label=None):\n",
    "    '''Search for specified address component and get the span.\n",
    "    Eg: get_address_span(address=\"221 B, Baker Street, London\",address_component=\"221\",label=\"BUILDING_NO\") would return (0,2,\"BUILDING_NO\")'''\n",
    "    \n",
    "    if address_component is None or (pd.isna(address_component) or str(address_component).lower() == 'nan'):\n",
    "        pass\n",
    "    else:\n",
    "        span=re.search(address_component,address)\n",
    "        return (span.start(),span.end(),label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1423dc48-b5c1-46ee-8154-813acfc59d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "50980 ROUTE 13  MIDDLEBURRY, IN.  ELKHART COUNTY\n",
      "MIDDLEBURY\n",
      "19\n",
      "6383 CRIMSON CIRCLE EAST DR (SOUTHPORT)  SPILL RAN OFF THIS PROPERTY, ALONG THE STREET CURB TOWARD SOUTH ABOUT 4-5 PROPERTIES AND INTO A STORM DRAIN\n",
      "6383 CRIMSON CIRCLE EAST DR (SOUTHPORT)  SPILL RAN OFF THIS PROPERTY, ALONG THE STREET CURB TOWARD SOUTH ABOUT 4-5 PROPERTIES AND INTO A STORM DRAIN\n",
      "91\n",
      "ST RD 124 AND 200 E\\  MT ETNA\n",
      "ST RD 124 AND 200 E\\  MT ETNA\n",
      "100\n",
      "1801 CRAWFORD ST  MIDDLETOWN, OH  45044\n",
      "54044\n",
      "164\n",
      "491 SOUTH COUNTRY RD. 800 EAST/ AVON YARD  INDIANAPOLIS, IN    HENDRICKS COUNTY  (NRC STATED MARION COUNTY)\n",
      "491 SOUTH COUNTRY RD. 800 EAST/ AVON YARD  INDIANAPOLIS, IN    HENDRICKS COUNTY  (NRC STATED MARION COUNTY)\n",
      "164\n",
      "491 SOUTH COUNTRY RD. 800 EAST/ AVON YARD  INDIANAPOLIS, IN    HENDRICKS COUNTY  (NRC STATED MARION COUNTY)\n",
      "SR 327 AND CR 10\n",
      "182\n",
      "INTERSECTION OF 223 E AND 200 S  DANVILLE, IN\n",
      "223 E AND 200 S '\n",
      "191\n",
      "GO LO  4321 E DUNES HIGHWAY (US12)  GARY\n",
      "GO LO  4321 E DUNES HIGHWAY (US12)  GARY\n",
      "193\n",
      "SECTION 18, 6 SOUTH AND 12 WEST  MOUNT VERNON, IN  (POSEY COUNTY)  CABORN ROAD NEAR INTERSECTION OF UPPER MOUNT VERNON ROAD.\n",
      "SECTION 18, 6 SOUTH AND 12 WEST  MOUNT VERNON, IN  (POSEY COUNTY)  CABORN ROAD NEAR INTERSECTION OF UPPER MOUNT VERNON ROAD.\n",
      "233\n",
      "4817 BROADWAY STREET, IN BASEMENT (HOME BUILT IN 1920'S)\n",
      "4817 BROADWAY STREET, IN BASEMENT (HOME BUILT IN 1920'S)\n",
      "244\n",
      "SW CORNER SR 14 AND CR 400 W  WINAMAC, IN  (PULASKI CO)\n",
      "SW CORNER SR 14 AND CR 400 W  WINAMAC, IN  (PULASKI CO)\n",
      "257\n",
      "LAPORTE CO  LAPORTE  I 90/80 MM 49.1\n",
      "LA PORTE\n",
      "259\n",
      "COUNTY LINE ROAD (SOUTH OF 300N)  LAPORTE   LAPORTE COUNTY\n",
      "COUNTY LINE ROAD (SOUTH OF 300N)  LAPORTE   LAPORTE COUNTY\n",
      "267\n",
      "KOKOMO, HOWARD COUNTY- 3449 E 100 N (ALLEGED)\n",
      "KOKOMO, HOWARD COUNTY- 3449 E 100 N (ALLEGED)\n",
      "272\n",
      "9731 SR 56  PATROIT, IN 47038  SWITZERLAND COUNTY\n",
      "PATRIOT\n",
      "[16, 19, 91, 100, 164, 164, 182, 191, 193, 233, 244, 257, 259, 267, 272]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "indexes = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    LOC = df['LOCATION'][i]\n",
    "    for thing in df:\n",
    "        address_component = df[thing][i]\n",
    "        if address_component is None or (pd.isna(address_component) or str(address_component).lower() == 'nan'):\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                span=re.search(address_component,LOC)\n",
    "            except:\n",
    "                indexes.append(i)\n",
    "            if span is None:\n",
    "                indexes.append(i)\n",
    "                print(i)\n",
    "                print(LOC)\n",
    "                print(address_component)\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2faf2087-1586-4841-8a53-8326f0047ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to remove these indexes because they are causing issues, sometimes its because of the ( or the / getting rid of these rexcords is ok\n",
    "\n",
    "df_filtered = df.drop(indexes)\n",
    "# print(df_filtered.head(30).to_markdown(index=False))\n",
    "\n",
    "\n",
    "# Save the modified DataFrame to a CSV file\n",
    "csv_filename = 'filtered_data.csv'\n",
    "df_filtered.to_csv(csv_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61aabf23-c23e-444a-b393-e44b18086784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "indexes_test = []\n",
    "\n",
    "for index, row in df_filtered.iterrows():\n",
    "    LOC = row['LOCATION']\n",
    "    for thing in df_filtered:\n",
    "        address_component = df_filtered[thing][index]\n",
    "        if address_component is None or (pd.isna(address_component) or str(address_component).lower() == 'nan'):\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                span=re.search(address_component,LOC)\n",
    "            except:\n",
    "                indexes_test.append(i)\n",
    "            if span is None:\n",
    "                indexes_test.append(i)\n",
    "\n",
    "print(indexes_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c0199c-e260-4f1c-9d38-b546529ac4e1",
   "metadata": {},
   "source": [
    "<h2>Split data into Train, Validation and Test sets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "362cd0b9-0d3c-4238-a658-49184dbb73d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the DataFrame: 286\n"
     ]
    }
   ],
   "source": [
    "# Get the number of rows in the DataFrame\n",
    "num_rows = df_filtered.shape[0]\n",
    "\n",
    "# Print the number of rows\n",
    "print(\"Number of rows in the DataFrame:\", num_rows)\n",
    "\n",
    "\n",
    "# # 70% of 259 is 182: 182 rows will be the training set\n",
    "\n",
    "df_train = df_filtered.head(182)\n",
    "\n",
    "# # 10% of 259 is 26: 26 rows will be the validation set\n",
    "\n",
    "df_val = df_filtered.iloc[182: 207]\n",
    "\n",
    "# # 20% of 300 is 52: 52ish rows will be the validation set\n",
    "df_test = df_filtered.iloc[208: 259]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97770c09-6767-463f-a346-6ceba34848cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def extend_list(entity_list,entity):\n",
    "    if pd.isna(entity):\n",
    "        return entity_list\n",
    "    else:\n",
    "        entity_list.append(entity)\n",
    "        return entity_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a9327b7-4226-4476-b3ba-c8fb6a62b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_entity_spans(df,tag_list):\n",
    "\n",
    "    '''Create entity spans for training/test datasets'''\n",
    "    df[\"AddressTag\"]=df.apply(lambda row:get_address_span(address=row['LOCATION'],address_component=row['ADDRESS'],label='ADDRESS'),axis=1)\n",
    "    df[\"CityTag\"]=df.apply(lambda row:get_address_span(address=row['LOCATION'],address_component=row['CITY'],label='CITY'),axis=1)\n",
    "    df[\"ZipTag\"]=df.apply(lambda row:get_address_span(address=row['LOCATION'],address_component=row['ZIP'],label='ZIP'),axis=1)\n",
    "    df[\"XTag\"]=df.apply(lambda row:get_address_span(address=row['LOCATION'],address_component=row['X'],label='X'),axis=1)\n",
    "    df[\"YTag\"]=df.apply(lambda row:get_address_span(address=row['LOCATION'],address_component=row['Y'],label='Y'),axis=1)\n",
    "    df['EmptySpan']=df.apply(lambda x: [], axis=1)\n",
    "\n",
    "    for i in tag_list:\n",
    "        df['EntitySpans']=df.apply(lambda row: extend_list(row['EmptySpan'],row[i]),axis=1)\n",
    "        df['EntitySpans']=df[['EntitySpans','LOCATION']].apply(lambda x: (x.iloc[1], x.iloc[0]),axis=1)\n",
    "    return df['EntitySpans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60e18ee7-2c96-4705-835b-342531c8bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def check_overlapping_spans(spans):\n",
    "    \"\"\"Utility function to check for overlapping spans\"\"\"\n",
    "    sorted_spans = sorted(spans, key=lambda span: span.start)\n",
    "    for i in range(1, len(sorted_spans)):\n",
    "        if sorted_spans[i].start < sorted_spans[i - 1].end:\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f78f0ce3-1e38-4627-94eb-d34fa6037306",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_doc_bin(training_data, nlp):\n",
    "    \n",
    "    '''Create DocBin object for building training/test corpus'''\n",
    "    # the DocBin will store the example documents\n",
    "    db = DocBin()\n",
    "    for text, annotations in training_data:\n",
    "        doc = nlp(text)  # Construct a Doc object\n",
    "        ents = []\n",
    "        for start, end, label in annotations:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span is not None:\n",
    "                ents.append(span)\n",
    "            # else:\n",
    "            #     print(span)\n",
    "            #     print(text)\n",
    "            #     print(annotations)\n",
    "        # Check for overlapping spans\n",
    "        if not check_overlapping_spans(ents):\n",
    "            doc.ents = ents\n",
    "            db.add(doc)\n",
    "        else:\n",
    "            # count += 1 #138\n",
    "            print(f\"Warning: Overlapping spans in text '{text}' with annotations '{annotations}'\")\n",
    "\n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b3d7b01-d021-4104-b425-1b1bf63a4223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Overlapping spans in text 'RIVER MILE 827.8  MT VERNON, IN' with annotations '[(0, 31, 'ADDRESS'), (18, 27, 'CITY')]'\n"
     ]
    }
   ],
   "source": [
    "#Load blank English model. This is needed for initializing a Document object for our training/test set.\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "#Define custom entity tag list\n",
    "tag_list=[\"AddressTag\",\"CityTag\",\"ZipTag\",\"XTag\",\"YTag\"]\n",
    "\n",
    "# Get entity spans\n",
    "df_entity_spans= create_entity_spans(df_train.astype(str),tag_list)\n",
    "training_data= df_entity_spans.values.tolist()\n",
    "\n",
    "\n",
    "# # Get & Persist DocBin to disk\n",
    "doc_bin_train= get_doc_bin(training_data,nlp)\n",
    "doc_bin_train.to_disk(\"training.spacy\")\n",
    "# ######################################\n",
    "\n",
    "\n",
    "# # Get entity spans\n",
    "df_entity_spans= create_entity_spans(df_val.astype(str),tag_list)\n",
    "validation_data= df_entity_spans.values.tolist()\n",
    "\n",
    "# # Get & Persist DocBin to disk\n",
    "doc_bin_test= get_doc_bin(validation_data,nlp)\n",
    "doc_bin_test.to_disk(\"Test.spacy\")\n",
    "# ##########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8137d5-a6bd-4958-bf19-729a5d444329",
   "metadata": {},
   "source": [
    "DocBin are used to package all the data into a single binary file.\n",
    "This file contains all the text data in a format optimized for speed and efficiency. It’s like putting all your documents into a compact, easy-to-carry container.\n",
    "When you need to work with the data, you can quickly load this DocBin file, unpack the documents, and perform various NLP tasks like text classification, entity recognition, or sentiment analysis efficiently.\n",
    "\n",
    "- config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15a7cbb8-c494-4a23-9bb6-4f489b70f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can run some code through the command line to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3560ba66-86ee-4bae-88b0-6db87d647e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npython -m spacy init fill-config base_config.cfg config\\\\config.cfg\\npython -m spacy train config\\\\config.cfg --paths.train training_dataset.spacy --paths.dev test.spacy --output output\\\\models --training.eval_frequency 10 --training.max_steps 300\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "python -m spacy init fill-config base_config.cfg config\\config.cfg\n",
    "python -m spacy train config\\config.cfg --paths.train training_dataset.spacy --paths.dev test.spacy --output output\\models --training.eval_frequency 10 --training.max_steps 300\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f25179bb-8c20-488b-b2e0-a96982f978c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nE    #       LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE\\n---  ------  --------  ------  ------  ------  ------\\n  0       0     65.07    6.90    5.33    9.76    0.07\\n  0      10    738.81    0.00    0.00    0.00    0.00\\n  1      20    295.99   45.28  100.00   29.27    0.45\\n  1      30    184.99   47.76   61.54   39.02    0.48\\n  2      40    569.01    9.52    9.30    9.76    0.10\\n  2      50    280.38   56.41   59.46   53.66    0.56\\n  3      60     97.77   59.74   63.89   56.10    0.60\\n  3      70    126.17   72.50   74.36   70.73    0.72\\n  4      80     71.42   73.68   80.00   68.29    0.74\\n  5      90     48.18   72.73   77.78   68.29    0.73\\n  5     100     33.35   74.70   73.81   75.61    0.75\\n  6     110     18.58   74.07   75.00   73.17    0.74\\n  7     120     24.04   76.71   87.50   68.29    0.77\\n  7     130     11.46   76.92   81.08   73.17    0.77\\n  8     140      7.35   72.29   71.43   73.17    0.72\\n  8     150     10.64   75.32   80.56   70.73    0.75\\n  9     160     10.74   77.50   79.49   75.61    0.77\\n 10     170      7.42   77.11   76.19   78.05    0.77\\n 10     180     11.04   78.57   76.74   80.49    0.79\\n 11     190      0.56   77.50   79.49   75.61    0.77\\n 12     200      8.41   77.50   79.49   75.61    0.77\\n 12     210     13.54   75.61   75.61   75.61    0.76\\n 13     220      7.26   79.01   80.00   78.05    0.79\\n 14     230     10.71   75.32   80.56   70.73    0.75\\n 14     240      0.83   76.54   77.50   75.61    0.77\\n 15     250      5.92   80.00   82.05   78.05    0.80\\n 16     260      5.97   80.00   82.05   78.05    0.80\\n 17     270      0.82   80.00   82.05   78.05    0.80\\n 17     280      3.36   77.92   83.33   73.17    0.78\\n 18     290      3.04   80.52   86.11   75.61    0.81\\n 19     300      4.51   81.82   76.60   87.80    0.82\\n\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "E    #       LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE\n",
    "---  ------  --------  ------  ------  ------  ------\n",
    "  0       0     65.07    6.90    5.33    9.76    0.07\n",
    "  0      10    738.81    0.00    0.00    0.00    0.00\n",
    "  1      20    295.99   45.28  100.00   29.27    0.45\n",
    "  1      30    184.99   47.76   61.54   39.02    0.48\n",
    "  2      40    569.01    9.52    9.30    9.76    0.10\n",
    "  2      50    280.38   56.41   59.46   53.66    0.56\n",
    "  3      60     97.77   59.74   63.89   56.10    0.60\n",
    "  3      70    126.17   72.50   74.36   70.73    0.72\n",
    "  4      80     71.42   73.68   80.00   68.29    0.74\n",
    "  5      90     48.18   72.73   77.78   68.29    0.73\n",
    "  5     100     33.35   74.70   73.81   75.61    0.75\n",
    "  6     110     18.58   74.07   75.00   73.17    0.74\n",
    "  7     120     24.04   76.71   87.50   68.29    0.77\n",
    "  7     130     11.46   76.92   81.08   73.17    0.77\n",
    "  8     140      7.35   72.29   71.43   73.17    0.72\n",
    "  8     150     10.64   75.32   80.56   70.73    0.75\n",
    "  9     160     10.74   77.50   79.49   75.61    0.77\n",
    " 10     170      7.42   77.11   76.19   78.05    0.77\n",
    " 10     180     11.04   78.57   76.74   80.49    0.79\n",
    " 11     190      0.56   77.50   79.49   75.61    0.77\n",
    " 12     200      8.41   77.50   79.49   75.61    0.77\n",
    " 12     210     13.54   75.61   75.61   75.61    0.76\n",
    " 13     220      7.26   79.01   80.00   78.05    0.79\n",
    " 14     230     10.71   75.32   80.56   70.73    0.75\n",
    " 14     240      0.83   76.54   77.50   75.61    0.77\n",
    " 15     250      5.92   80.00   82.05   78.05    0.80\n",
    " 16     260      5.97   80.00   82.05   78.05    0.80\n",
    " 17     270      0.82   80.00   82.05   78.05    0.80\n",
    " 17     280      3.36   77.92   83.33   73.17    0.78\n",
    " 18     290      3.04   80.52   86.11   75.61    0.81\n",
    " 19     300      4.51   81.82   76.60   87.80    0.82\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ef40c-9f86-47cb-9140-587587e37288",
   "metadata": {},
   "source": [
    "this model take 300 steps. and by the end of it our losses have decreased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb88d8da-5420-473a-ab50-d0a87fe4c8c9",
   "metadata": {},
   "source": [
    "<h1>Test the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d248beb-ffc7-4d4e-be6e-2dfb171f1882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the parsed address the model predicted: 87TH AND PULASKI RD\n",
      "this is the pased address I manually parsed: 87TH AND PULASKI RD\n",
      "yes\n",
      "this is the parsed address the model predicted: 6795 E CR 600\n",
      "this is the pased address I manually parsed: 6795 E CR 600\n",
      "yes\n",
      "this is the parsed address the model predicted: 600 EAST DALLAS ROAD\n",
      "this is the pased address I manually parsed: 600 EAST DALLAS ROAD\n",
      "yes\n",
      "this is the parsed address the model predicted: 1030 E MARKET\n",
      "this is the pased address I manually parsed: 1030 E MARKET\n",
      "yes\n",
      "this is the parsed address the model predicted: 301 N RANDOLPH ST\n",
      "this is the pased address I manually parsed: 301 N RANDOLPH ST\n",
      "yes\n",
      "this is the parsed address the model predicted: 1119 S SR 3\n",
      "this is the pased address I manually parsed: 1119 S SR 3\n",
      "yes\n",
      "this is the parsed address the model predicted: 8947 E DELAWARE PARKWAY\n",
      "this is the pased address I manually parsed: 8947 E DELAWARE PARKWAY\n",
      "yes\n",
      "this is the parsed address the model predicted: DR. JAMES A DILLON PARK\n",
      "this is the pased address I manually parsed: EDENSHALL LANE AND KIRKENDALL CREEK\n",
      "no\n",
      "this is the parsed address the model predicted: US 31\n",
      "this is the pased address I manually parsed: nan\n",
      "no\n",
      "this is the parsed address the model predicted: 301 N HIGH ST\n",
      "this is the pased address I manually parsed: 301 N HIGH ST\n",
      "yes\n",
      "this is the parsed address the model predicted: 1117 N 600 E\n",
      "this is the pased address I manually parsed: 1117 N 600 E\n",
      "yes\n",
      "this is the parsed address the model predicted: BEHIND 207 EAST MAIN ST\n",
      "this is the pased address I manually parsed: nan\n",
      "no\n",
      "this is the parsed address the model predicted: 2705 HARTS GRAVEL ROAD FRED SCHNELL FARM\n",
      "this is the pased address I manually parsed: 2705 HARTS GRAVEL ROAD\n",
      "no\n",
      "this is the parsed address the model predicted: 15825 LITTLE EAGLE CREEK AVE\n",
      "this is the pased address I manually parsed: 15825 LITTLE EAGLE CREEK AVE\n",
      "yes\n",
      "this is the parsed address the model predicted: BEAVER DAMN LAKE\n",
      "this is the pased address I manually parsed: nan\n",
      "no\n",
      "this is the parsed address the model predicted: 361 W.47TH STREET\n",
      "this is the pased address I manually parsed: 361 W.47TH STREET\n",
      "yes\n",
      "this is the parsed address the model predicted: 704 JEFFERSON PARK DR\n",
      "this is the pased address I manually parsed: 704 JEFFERSON PARK DR\n",
      "yes\n",
      "this is the parsed address the model predicted: 5 MILES N\n",
      "this is the pased address I manually parsed: nan\n",
      "no\n",
      "this is the parsed address the model predicted: MILLHOUSEN ROAD AND CR 650 W.\n",
      "this is the pased address I manually parsed: MILLHOUSEN ROAD AND CR 650 W.\n",
      "yes\n",
      "this is the parsed address the model predicted: 1824 LANARKSHIRE DR\n",
      "this is the pased address I manually parsed: 1824 LANARKSHIRE DR\n",
      "yes\n",
      "this is the parsed address the model predicted: 5411 W. 78TH STREET\n",
      "this is the pased address I manually parsed: 5411 W. 78TH STREET\n",
      "yes\n",
      "this is the parsed address the model predicted: 25915 SE FRONTAGE ROAD\n",
      "this is the pased address I manually parsed: 25915 SE FRONTAGE ROAD\n",
      "yes\n",
      "this is the parsed address the model predicted: MILE POST D146\n",
      "this is the pased address I manually parsed: nan\n",
      "no\n",
      "this is the parsed address the model predicted: 814 RICHMOND AVE\n",
      "this is the pased address I manually parsed: 814 RICHMOND AVE\n",
      "yes\n",
      "this is the parsed address the model predicted: 27201 EARLY RD\n",
      "this is the pased address I manually parsed: 27201 EARLY RD\n",
      "yes\n",
      "this is the parsed address the model predicted: 29TH AND LASALLE\n",
      "this is the pased address I manually parsed: 29TH AND LASALLE\n",
      "yes\n",
      "this is the parsed address the model predicted: 1650 US 41\n",
      "this is the pased address I manually parsed: 1650 US 41\n",
      "yes\n",
      "this is the parsed address the model predicted: 528 E SR 56\n",
      "this is the pased address I manually parsed: 528 E SR 56\n",
      "yes\n",
      "this is the parsed address the model predicted: 1601 E MAIN STREET\n",
      "this is the pased address I manually parsed: 1601 E MAIN STREET\n",
      "yes\n",
      "this is the parsed address the model predicted: 3101 BRIDGEWAY DRIVE\n",
      "this is the pased address I manually parsed: 3101 BRIDGEWAY DRIVE\n",
      "yes\n",
      "this is the parsed address the model predicted: 701 CASINO CENTER DR\n",
      "this is the pased address I manually parsed: 701 CASINO CENTER DR\n",
      "yes\n",
      "this is the parsed address the model predicted: 2243 SR 43\n",
      "this is the pased address I manually parsed: 2243 SR 43\n",
      "yes\n",
      "this is the parsed address the model predicted: 8310 SR 3\n",
      "this is the pased address I manually parsed: 8310 SR 3\n",
      "yes\n",
      "33\n",
      "26\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# df_test\n",
    "\n",
    "\n",
    "nlp=spacy.load(\"output\\models\\model-best\")\n",
    "\n",
    "###Prediction output###\n",
    "\n",
    "\n",
    "\n",
    "# location_list = df_test['LOCATION']\n",
    "# correct_address = df_test['ADDRESS']\n",
    "# correct_city = df_test['CITY']\n",
    "# correct_ZIP = df_test['ZIP']\n",
    "# correct_X = df_test['X']\n",
    "# correct_Y = df_test['Y']\n",
    "\n",
    "count_right_address = 0\n",
    "count_right_city = 0\n",
    "counter =0\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    LOC = row['LOCATION']\n",
    "    doc=nlp(LOC)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'ADDRESS':\n",
    "            print('this is the parsed address the model predicted: ' + ent.text)\n",
    "            print('this is the pased address I manually parsed: ' + str(row['ADDRESS']))\n",
    "            if ent.text ==str(row['ADDRESS']):\n",
    "                count_right_address += 1\n",
    "                print('yes')\n",
    "            else:\n",
    "                print('no')\n",
    "            \n",
    "        elif ent.label_ == 'CITY':\n",
    "            # print('this is the parsed city the model predicted: ' + ent.text)\n",
    "            # print('this is the pased city I manually parsed: ' + str(row['CITY']))\n",
    "            if ent.text ==str(row['CITY']):\n",
    "                count_right_city += 1\n",
    "    counter+=1\n",
    "                    \n",
    "print(count_right_city)    \n",
    "print(count_right_address)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e635bf-e9c0-4025-9c3b-3922021f3363",
   "metadata": {},
   "source": [
    "in the training dataset: the model score about a 50% just parsing the addresses (26/51) and about a 60% with city values (33/51)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2967e4-ba7b-45f6-b54a-83a76a00e1bc",
   "metadata": {},
   "source": [
    "<h1> Testing Raw data with the model:</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61b7f6e5-db5e-499b-bc80-233934e19cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address string -> 135th & New Ave, Lemont, IL  60439  \n",
      "Parsed address -> [('135th & New', 'ADDRESS'), ('Lemont', 'CITY'), ('60439', 'ZIP')]\n",
      "******\n",
      "Address string -> 135th & New Ave  Lemont, IL  60439\n",
      "Parsed address -> [('135th & New Ave', 'ADDRESS'), ('Lemont', 'CITY'), ('60439', 'ZIP')]\n",
      "******\n",
      "Address string -> Ranards Hauling, Removal and Recycling  2772 North State Road 157\n",
      "Parsed address -> [('2772 North State Road 157', 'ADDRESS')]\n",
      "******\n",
      "Address string -> Milepost 298.3  Newell, IL\n",
      "Parsed address -> [('Newell', 'CITY')]\n",
      "******\n",
      "Address string -> I 70 East Bound Mile Marker 112  Greenfield, IN\n",
      "Parsed address -> [('Greenfield', 'CITY')]\n",
      "******\n",
      "Address string -> Toll Road MM 23 EB pavement and shoulder\n",
      "Parsed address -> [('Toll Road MM 23', 'ADDRESS')]\n",
      "******\n",
      "Address string -> Lake Michigan & Lake Front Whihala Beach  Whiting, IN\n",
      "Parsed address -> [('Lake Front Whihala Beach', 'CITY'), ('Whiting', 'CITY')]\n",
      "******\n",
      "Address string -> 6383 CRIMSON CIRCLE EAST DR (SOUTHPORT)  SPILL RAN OFF THIS PROPERTY, ALONG THE STREET CURB TOWARD SOUTH ABOUT 4-5 PROPERTIES AND INTO A STORM DRAIN\n",
      "Parsed address -> [('6383 CRIMSON CIRCLE EAST DR', 'ADDRESS'), ('SPILL RAN', 'CITY'), ('5 PROPERTIES AND INTO A STORM DRAIN', 'ADDRESS')]\n",
      "******\n",
      "Address string -> MM 124 I 80/90 W BOUND  HOWE IN  LAGRANGE CO\n",
      "Parsed address -> [('80/90 W BOUND', 'ADDRESS'), ('HOWE', 'CITY')]\n",
      "******\n",
      "Address string -> TIVOLI THEATER  26 OR 15 N WASHINGTON ST  SPENCER, OWEN CO  \n",
      "Parsed address -> [('TIVOLI THEATER', 'CITY'), ('SPENCER', 'CITY')]\n",
      "******\n",
      "Address string -> PLASTICS PLANT\n",
      "Parsed address -> []\n",
      "******\n",
      "Address string -> 4190 S CR  350 W.  Commercial slaughter house. Failing septic system, with absorption field lateral blow out in field adj creek, located NE of facility\n",
      "Parsed address -> [('4190 S CR', 'ADDRESS'), ('Commercial slaughter', 'CITY'), ('house. Failing', 'ADDRESS')]\n",
      "******\n",
      "Address string -> 11141 Canal Road  Sharonville, OH\n",
      "Parsed address -> [('11141 Canal Road', 'ADDRESS'), ('Sharonville', 'CITY')]\n",
      "******\n",
      "Address string -> Martin Yard  Bedford Park, IL  \n",
      "Parsed address -> [('Bedford Park', 'CITY')]\n",
      "******\n",
      "Address string -> alley off of Pine Street Loogootee\n",
      "Parsed address -> [('alley off of Pine Street', 'ADDRESS')]\n",
      "******\n",
      "Address string -> 2815 INDIANPOLIS BLVD  WHITING, IN 46394\n",
      "Parsed address -> [('2815 INDIANPOLIS BLVD', 'ADDRESS'), ('WHITING', 'CITY'), ('46394', 'ZIP')]\n",
      "******\n",
      "Address string -> Mile Post M271  Louisville\n",
      "Parsed address -> [('Louisville', 'CITY')]\n",
      "******\n",
      "Address string -> 1605 N SHADELAND AVE  INDIANAPOLIS, IN  - MARION COUNTY  SPEEDWAY GAS STATION\n",
      "Parsed address -> [('1605 N SHADELAND AVE', 'ADDRESS'), ('INDIANAPOLIS', 'CITY'), ('- MARION', 'CITY'), ('SPEEDWAY GAS STATION', 'CITY')]\n",
      "******\n",
      "Address string -> River Mile 771\n",
      "Parsed address -> [('River Mile 771', 'ADDRESS')]\n",
      "******\n",
      "Address string -> 2505 Data Drive  Jeffersontown, KY\n",
      "Parsed address -> [('2505 Data Drive', 'ADDRESS'), ('Jeffersontown', 'CITY')]\n",
      "******\n",
      "Address string -> River Mile 471.7 (Ohio River)  Cincinnati, OH\n",
      "Parsed address -> [('Cincinnati', 'CITY')]\n",
      "******\n",
      "Address string -> Sabic  1 Lexan Lane  Mt. Vernon, IN  Posey County\n",
      "Parsed address -> [('Mt. Vernon', 'CITY')]\n",
      "******\n",
      "Address string -> 191 N Benton, Rail Yard, # 1 track\n",
      "Parsed address -> []\n",
      "******\n",
      "Address string -> SR 200 N & 950 E  Idaville, IN\n",
      "Parsed address -> [('SR 200 N', 'ADDRESS'), ('Idaville', 'CITY')]\n",
      "******\n",
      "Address string -> MM 31-34 I 80/90 W BOUND CHESTERTON IN\n",
      "Parsed address -> [('34 I 80/90 W BOUND CHESTERTON', 'ADDRESS')]\n",
      "******\n",
      "Address string -> I69, 26 MILE MARKER, MEDIAN DITCH (SCATTERFIELD ROAD EXIT)  ANDERSON  MADISON\n",
      "Parsed address -> [('ANDERSON', 'CITY')]\n",
      "******\n",
      "Address string -> I69, 26 MILE MARKER, MEDIAN DITCH (SCATTERFIELD ROAD EXIT)  ANDERSON  MADISON\n",
      "Parsed address -> [('ANDERSON', 'CITY')]\n",
      "******\n",
      "Address string -> Henry Co  I-70 West bound, roughly 0.25 mile west of highway 109\n",
      "Parsed address -> []\n",
      "******\n",
      "Address string -> Boone County  I65 Mile Marker 128, median\n",
      "Parsed address -> []\n",
      "******\n",
      "Address string -> Toll Road MM 26.7 WB\n",
      "Parsed address -> [('Toll Road MM 26.7 WB', 'ADDRESS')]\n",
      "******\n",
      "Address string -> I-94 WB at the 12.5mm\n",
      "Parsed address -> []\n",
      "******\n",
      "Address string -> 501 west 6th street/former roofing facility\n",
      "Parsed address -> [('501 west 6th street', 'ADDRESS'), ('former roofing facility', 'CITY')]\n",
      "******\n",
      "Address string -> SR 356 N OF   LEXINGTON IN  SCOTT CO\n",
      "Parsed address -> [('SR 356 N', 'ADDRESS'), ('LEXINGTON', 'CITY')]\n",
      "******\n",
      "Address string -> Henry County  I-70 Mile marker 113 EB\n",
      "Parsed address -> []\n",
      "******\n",
      "Address string -> I-69 MM 111\n",
      "Parsed address -> [('I-69 MM 111', 'ADDRESS')]\n",
      "******\n",
      "Address string -> Proviso Rail Yard  5050 West Lake St  Northlake, IL\n",
      "Parsed address -> [('5050 West Lake St', 'ADDRESS'), ('Northlake', 'CITY')]\n",
      "******\n",
      "Address string -> area on south side of parking lot of the Creekside Inn Restaurant, located at 613 Lafayette Ave\n",
      "Parsed address -> [('on', 'ZIP'), ('south side', 'CITY'), ('the Creekside', 'ADDRESS'), ('613 Lafayette Ave', 'ADDRESS')]\n",
      "******\n",
      "Address string -> 2815 Indianapolis Blvd.  Whiting, IN.  Lake County\n",
      "Parsed address -> [('Whiting', 'CITY')]\n",
      "******\n",
      "Address string -> Unnamed creek near 2125 South CR 125 West\n",
      "Parsed address -> [('2125 South CR 125 West', 'ADDRESS')]\n",
      "******\n",
      "Address string -> 2815 Indianapolis Blvd  Whiting, IN  46394\n",
      "Parsed address -> [('Whiting', 'CITY'), ('46394', 'ZIP')]\n",
      "******\n",
      "Address string -> 1 North Broadway; outfall 018; Grand Calumet river\n",
      "Parsed address -> [('outfall 018; Grand Calumet', 'ADDRESS')]\n",
      "******\n",
      "Address string -> 4350 Campground Road  Louisville, KY  40216\n",
      "Parsed address -> [('4350 Campground Road', 'ADDRESS'), ('Louisville', 'CITY'), ('40216', 'ZIP')]\n",
      "******\n",
      "Address string -> 410 E Columbus Drive\n",
      "Parsed address -> [('410 E Columbus', 'ADDRESS')]\n",
      "******\n",
      "Address string -> Milepost 342  Bryan, OH\n",
      "Parsed address -> [('Bryan', 'CITY')]\n",
      "******\n",
      "Address string -> 700 N EASTERN AVE   CONNERSVILLE IN  FAYETTE CO\n",
      "Parsed address -> [('700 N EASTERN AVE', 'ADDRESS'), ('CONNERSVILLE', 'CITY')]\n",
      "******\n",
      "Address string -> 1049 US HIGHWAY 41 SCHERERVILLE IN;  Across 41 from Menards\n",
      "Parsed address -> [('1049 US HIGHWAY 41 SCHERERVILLE', 'ADDRESS'), ('Across 41 from', 'CITY')]\n",
      "******\n",
      "Address string -> 125 Twin Oaks Drive  Joliette, IL\n",
      "Parsed address -> [('Joliette', 'CITY')]\n",
      "******\n",
      "Address string -> PEARL ST   LAUREL IN  FRANKLIN CO\n",
      "Parsed address -> [('LAUREL', 'CITY')]\n",
      "******\n",
      "Address string -> Mile Post 18.91  Blue Island, IL\n",
      "Parsed address -> [('Blue', 'CITY')]\n",
      "******\n",
      "Address string -> 4401 Bells Lane  Louisville, KY  40216\n",
      "Parsed address -> [('4401 Bells Lane', 'ADDRESS'), ('Louisville', 'CITY'), ('40216', 'ZIP')]\n",
      "******\n",
      "Address string -> 9103 North Greenwood  Niles, IL\n",
      "Parsed address -> [('9103 North Greenwood', 'ADDRESS'), ('Niles', 'CITY')]\n",
      "******\n",
      "Address string -> 3008 Acoma Drive  Indianapolis, IN  Marion County\n",
      "Parsed address -> [('3008 Acoma Drive', 'ADDRESS'), ('Indianapolis', 'CITY')]\n",
      "******\n",
      "Address string -> US HWY 41 South  Robards, KY  42452\n",
      "Parsed address -> [('US HWY 41 South', 'ADDRESS'), ('Robards', 'CITY'), ('42452', 'ZIP')]\n",
      "******\n",
      "Address string -> 3700 S Harding,  Unit 7 scrubber pipeline over Lick Creek.  The release occurred roughly 100 feet south of Lick Creek and material flowed north into the creek.  \n",
      "Parsed address -> [('3700 S Harding', 'ADDRESS'), ('Unit 7 scrubber pipeline over', 'CITY'), ('The', 'CITY'), ('south of', 'CITY')]\n",
      "******\n",
      "Address string -> I-70 WB MM 94(NORTH SIDE)  MARION COUNTY  \n",
      "Parsed address -> []\n",
      "******\n",
      "Address string -> BP AMOCO REFINERY  2815 INDIANAPOLIS BLVD  WHITING, LAKE CO\n",
      "Parsed address -> [('BP AMOCO REFINERY', 'ADDRESS'), ('WHITING', 'CITY')]\n",
      "******\n",
      "Address string -> 2424 BREMER RD  FORT WAYNE  ALLEN CO  OLD DOMINION FREIGHT HUB  \n",
      "Parsed address -> [('2424 BREMER RD', 'ADDRESS'), ('FORT WAYNE', 'CITY')]\n",
      "******\n",
      "Address string -> Columbia Avenue Lift Station\n",
      "Parsed address -> [('Columbia Avenue Lift Station', 'ADDRESS')]\n",
      "******\n",
      "Address string -> Kerry Ingredents gravel lot\n",
      "Parsed address -> []\n",
      "******\n",
      "Address string -> 200 Trowbridge Rd  Indianapolis, Marion Co  INDIANA RR YARD\n",
      "Parsed address -> [('200 Trowbridge Rd', 'ADDRESS'), ('Indianapolis', 'CITY')]\n",
      "******\n",
      "Address string -> 487 Corn Creek Road  Bedford, KY\n",
      "Parsed address -> [('487 Corn Creek Road', 'ADDRESS'), ('Bedford', 'CITY')]\n",
      "******\n",
      "Address string -> 1440 NW L STREET  RICHMOND IN  WAYNE CO\n",
      "Parsed address -> [('1440 NW L STREET', 'ADDRESS'), ('RICHMOND', 'CITY')]\n",
      "******\n",
      "Address string -> Ohio River, River Mile 475  Cincinnati, OH\n",
      "Parsed address -> [('River', 'CITY'), ('Cincinnati', 'CITY')]\n",
      "******\n",
      "Address string -> Dependable Metal Treating  902 East Dowling  Kendallville, IN. 46755\n",
      "Parsed address -> [('Dependable Metal Treating', 'ADDRESS'), ('902 East', 'CITY'), ('Kendallville', 'CITY')]\n",
      "******\n",
      "Address string -> South side of I 70 East Bound between 26.5 and 27 milemarkers  Brazil, IN  Clay County\n",
      "Parsed address -> [('South side of I 70', 'ADDRESS'), ('between 26.5 and 27 milemarkers', 'ADDRESS'), ('Brazil', 'CITY')]\n",
      "******\n",
      "Address string -> 2403 US 31 LOT 51  PLYMOUTH  MARSHALL CO\n",
      "Parsed address -> [('2403 US 31', 'ADDRESS'), ('PLYMOUTH', 'CITY')]\n",
      "******\n",
      "Address string -> 3044 Northg Fuller Drive\n",
      "Parsed address -> [('3044 Northg Fuller Drive', 'ADDRESS')]\n",
      "******\n",
      "Address string -> Marion County  46th & Post  Lawrence, IN\n",
      "Parsed address -> [('46th &', 'CITY'), ('Lawrence', 'CITY')]\n",
      "******\n",
      "Address string -> Marion County  3041 E  Bradbury Ave.  Indianapolis, IN\n",
      "Parsed address -> [('3041 E  ', 'ADDRESS'), ('Bradbury Ave.', 'CITY'), ('Indianapolis', 'CITY')]\n",
      "******\n",
      "Address string -> 25915 SE Frontage Rd  Channahon, IL\n",
      "Parsed address -> [('25915 SE Frontage Rd', 'ADDRESS'), ('Channahon', 'CITY')]\n",
      "******\n",
      "Address string -> Jay County  513 W Walnut St.  Portland, IN\n",
      "Parsed address -> [('513 W Walnut St.', 'ADDRESS'), ('Portland', 'CITY')]\n",
      "******\n",
      "Address string -> 4130 RIDGE RD  ANDERSON  MADISON CO\n",
      "Parsed address -> [('4130 RIDGE RD', 'ADDRESS'), ('ANDERSON', 'CITY')]\n",
      "******\n",
      "Address string -> Jackson County  I-65 SB Milemarker 53  Seymour, IN\n",
      "Parsed address -> [('Seymour', 'CITY')]\n",
      "******\n",
      "Address string -> 1338 Grant Street\n",
      "Parsed address -> [('1338 Grant Street', 'ADDRESS')]\n",
      "******\n",
      "Address string -> 2700 S Belmont  indianapolis, Marion Co\n",
      "Parsed address -> [('2700 S Belmont', 'ADDRESS'), ('indianapolis', 'CITY')]\n",
      "******\n",
      "Address string -> Hickory Ridge Apartments  near 57th Avenue and Cleveland Street  Merrillville, IN.    Lake County\n",
      "Parsed address -> [('Hickory Ridge', 'CITY'), ('near 57th Avenue and Cleveland Street', 'CITY'), ('Merrillville', 'CITY')]\n",
      "******\n",
      "Address string -> 6528 Grandview Dr   Indianapolis, IN  Marion County\n",
      "Parsed address -> [('6528 Grandview Dr', 'ADDRESS'), ('Indianapolis', 'CITY')]\n",
      "******\n",
      "Address string -> 7611 BROOKVIEW LN  INDIANAPOLIS  MARIONCO\n",
      "Parsed address -> [('7611 BROOKVIEW LN', 'ADDRESS'), ('INDIANAPOLIS', 'CITY'), ('MARIONCO', 'CITY')]\n",
      "******\n",
      "Address string -> 4324 Columbia\n",
      "Parsed address -> [('4324 Columbia', 'ADDRESS')]\n",
      "******\n",
      "Address string -> behind 214 Foster, Attica, Fountain County  outside the Comcast Satelight Dish fence\n",
      "Parsed address -> [('behind 214 Foster', 'ADDRESS'), ('outside', 'ZIP'), ('Comcast Satelight', 'CITY')]\n",
      "******\n",
      "Address string -> 9075 S 250 E  KEYSTONE  WELLS CO  FORMERLY KNOWN AS ROCK CREEK DAIRY\n",
      "Parsed address -> [('9075 S 250 E', 'ADDRESS'), ('KEYSTONE', 'CITY'), ('FORMERLY KNOWN', 'CITY')]\n",
      "******\n",
      "Address string -> I-75 SB At Ohio Rout 122  Middletown, OH\n",
      "Parsed address -> [('I-75 SB At Ohio Rout 122', 'ADDRESS'), ('Middletown', 'CITY')]\n",
      "******\n",
      "Address string -> Intersection of CR 400w and 12 Street\n",
      "Parsed address -> [('CR 400w and 12 Street', 'ADDRESS')]\n",
      "******\n",
      "Address string -> Rudy road & Dewey Lake Rd  Dowagiac, MI\n",
      "Parsed address -> [('Dowagiac', 'CITY')]\n",
      "******\n",
      "Address string -> 1250 South Meridian  Jasonville, Greene County\n",
      "Parsed address -> [('1250 South Meridian', 'ADDRESS'), ('Jasonville', 'CITY')]\n",
      "******\n",
      "Address string -> 3150 Bencyn Court\n",
      "Parsed address -> [('3150 Bencyn Court', 'ADDRESS')]\n",
      "******\n",
      "Address string -> 2815 Indiananpolis Blvd\n",
      "Parsed address -> [('2815 Indiananpolis Blvd', 'ADDRESS')]\n",
      "******\n",
      "Address string -> Intersection of Valley Farms Road and Valley Farms Court\n",
      "Parsed address -> [('Valley Farms Road and Valley Farms Court', 'ADDRESS')]\n",
      "******\n",
      "Address string ->  morse resevoir Bridge at main street  Cicero, Hamilton\n",
      "Parsed address -> [('morse', 'CITY'), ('Cicero', 'CITY')]\n",
      "******\n",
      "Address string -> 212 South 5th AVE  Princeton,  Gibson Co\n",
      "Parsed address -> [('212 South 5th AVE', 'ADDRESS'), ('Princeton', 'CITY')]\n",
      "******\n",
      "Address string -> 304 KNOX ST  PETERSBURG IN  PIKE CO\n",
      "Parsed address -> [('304 KNOX ST', 'ADDRESS'), ('PETERSBURG', 'CITY')]\n",
      "******\n",
      "Address string -> 5505 St Road 159 across the street  Dugger, Sullivan co\n",
      "Parsed address -> [('5505 St Road 159 across', 'ADDRESS'), ('Dugger', 'CITY')]\n",
      "******\n",
      "Address string -> approximately 2156 Brown Chappel Road\n",
      "Parsed address -> [('approximately 2156 Brown Chappel Road', 'ADDRESS')]\n",
      "******\n",
      "Address string -> On ramp of Exit 9 North Bound on to I-65  Sellersburg, IN.  Clark County\n",
      "Parsed address -> [('ramp of', 'CITY'), ('Sellersburg', 'CITY')]\n",
      "******\n",
      "Address string -> 4401 Dells LN  Louisville, KY  40211\n",
      "Parsed address -> [('4401 Dells LN', 'ADDRESS'), ('Louisville', 'CITY'), ('40211', 'ZIP')]\n",
      "******\n",
      "Address string -> MUNCIE RAILROAD YARD\n",
      "Parsed address -> []\n",
      "******\n",
      "Address string -> Fuchs Farm 12954 N SR 61 Lynville\n",
      "Parsed address -> [('Fuchs Farm 12954 N SR 61 Lynville', 'ADDRESS')]\n",
      "******\n",
      "Address string -> Marion County  6243 W Washington St  Indianapolis, IN  \n",
      "Parsed address -> [('6243 W Washington St', 'ADDRESS'), ('Indianapolis', 'CITY')]\n",
      "******\n",
      "Address string -> 1130 S Dixon St (behind this transfer station)  Kokomo, IN  46901  HOWARD CO\n",
      "Parsed address -> [('1130 S Dixon St', 'ADDRESS'), ('Kokomo', 'CITY'), ('46901', 'ZIP')]\n",
      "******\n"
     ]
    }
   ],
   "source": [
    "# testing the model with raw data \n",
    "\n",
    "nlp=spacy.load(\"output\\models\\model-best\")\n",
    "\n",
    "\n",
    "df_RAW=pd.read_csv(\"ADDRESS_DATA_RAW.csv\",sep=\",\",dtype=str)\n",
    "\n",
    "\n",
    "###Prediction output###\n",
    "\n",
    "\n",
    "\n",
    "address_list = df_RAW['LOCATION'][1:100]\n",
    "\n",
    "for address in address_list:\n",
    "    doc=nlp(address)\n",
    "    ent_list=[(ent.text, ent.label_) for ent in doc.ents]\n",
    "    print(\"Address string -> \"+address)\n",
    "    print(\"Parsed address -> \"+str(ent_list))\n",
    "    print(\"******\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0364f5-51ae-4fbf-9b0e-aa918efeb7fa",
   "metadata": {},
   "source": [
    "At a glance these values look pretty good! Even though the test dataset scored about a 50% in accuracy. This shows that for the data to parsed carefully more training data with parsed addresses will be nessesary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b728996a-943a-455b-895f-8b2c08f41dc0",
   "metadata": {},
   "source": [
    "<h1>Next steps: The Future</h1>\n",
    "\n",
    "\n",
    "ArcGIS has a library itself called: arcgis.learn, which also uses spaCy in coorperated with geocoding and ESRI. In the future we can incoorperate this into the workflow as well. \n",
    "\n",
    "Better training data = better results. In the future using larger training data to train our model will result in better outcomes\n",
    "\n",
    "Exploring the parameters in the config file like learning rate etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665d3c8-66d8-43e0-815e-9c49ea6a237f",
   "metadata": {},
   "source": [
    "<h1>References</h1>\n",
    "  I used a lot of the functions from this repository in this medium article:\n",
    "  \n",
    "  [Building and Address Parser with spaCy](<https://medium.com/globant/building-an-address-parser-with-spacy-e3376b7cff>). \n",
    "\n",
    "\n",
    "  An example of the ArcGis Learn module:\n",
    "  \n",
    "   [Information extraction from Madison city crime incident reports using Deep Learning](<https://developers.arcgis.com/python/samples/information-extraction-from-madison-city-crime-incident-reports-using-deep-learning/#References>). \n",
    "\n",
    " \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a0b1a-9c7d-483b-a0ff-3539473b9088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
